FAIR AND EXPLAINABLE LOAN ELIGIBILITY PREDICTOR

Fair and Explainable Loan Eligibility Prediction using HMDA data.
This project combines XGBoost, SHAP explainability, and fairness analysis to build a transparent, reproducible loan approval model with a Streamlit interface.

This project focuses on predicting loan eligibility using the HMDA dataset with a backend-only machine learning pipeline. The core work is contained in Loan_Eligibility.ipynb, where the dataset (cleaned_strict.csv) is loaded, cleaned, and processed according to the rules documented in cleaning_log.json. Encodings for categorical variables are preserved in encodings.json, while the final features used for model training are listed in feature_list.txt. The target variable is approved_flag, representing whether a loan was approved or denied. The cleaned dataset contains 4,999 rows and 74 columns after dropping redundant fields, imputing missing values, and removing duplicates. Model training is performed using XGBoost, with hyperparameters optimized by Optuna, and the final trained model is stored as xgboost_best.pkl. Evaluation includes standard classification metrics such as accuracy, precision, recall, F1, and ROC-AUC, along with fairness checks using Fairlearn and feature explainability with SHAP. Basic exploratory plots, such as the distribution of approvals, loan amounts, incomes, and applicant ages, help understand the data before modeling. To reproduce results, install dependencies from requirements.txt, run the notebook, and artifacts will be generated automatically. For inference, the saved model can be loaded with joblib, aligned with the feature_list.txt schema, and used to generate predictions and probabilities for new applications. This setup provides a reproducible, research-ready workflow without the need for any frontend interface.
This project is licensed under the MIT License. See LICENSE for details.
